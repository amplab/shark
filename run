#!/bin/bash

# This file is used to launch Shark, both on masters and slaves.

# Figure out where the Scala framework is installed
FWDIR="$(cd `dirname $0`; pwd)"

# Export this as SPARK_HOME
export SPARK_HOME="$FWDIR"
export SHARK_HOME="$FWDIR"

# Load environment variables from conf/shark-env.sh, if it exists
if [ -e $SHARK_HOME/conf/shark-env.sh ] ; then
  . $SHARK_HOME/conf/shark-env.sh
fi

# Hive related section.
if [ "x$HIVE_HOME" == "x" ] ; then
    echo "No HIVE_HOME specified. Please set HIVE_HOME"
    exit 1
fi

# Check for optionally specified configuration file path
if [ "x$HIVE_CONF_DIR" == "x" ] ; then
    HIVE_CONF_DIR="$HIVE_HOME/conf"
fi

if [ -f "${HIVE_CONF_DIR}/hive-env.sh" ]; then
  . "${HIVE_CONF_DIR}/hive-env.sh"
fi

# Build up classpath
CLASSPATH+=":$SPARK_CLASSPATH:$SHARK_HOME/target/scala-$SCALA_VERSION/classes"
CLASSPATH+=":$SHARK_HOME/target/scala-$SCALA_VERSION/test-classes"
CLASSPATH+=:$HIVE_CONF_DIR

if [ "x$HADOOP_HOME" == "x" ] ; then
    echo "No HADOOP_HOME specified. Shark will run in local-mode"
else
    CLASSPATH+=:$HADOOP_HOME/conf
fi

# Add Shark jars.
for jar in `find $SHARK_HOME/lib -name '*jar'`; do
  CLASSPATH+=:$jar
done
for jar in `find $SHARK_HOME/lib_managed/jars -name '*jar'`; do
  CLASSPATH+=:$jar
done
for jar in `find $SHARK_HOME/lib_managed/bundles -name '*jar'`; do
  CLASSPATH+=:$jar
done

# Add Hive jars.
for jar in `find $HIVE_HOME/lib -name '*jar'`; do
  # Ignore the logging library since it has already been included with the Spark jar.
  if [[ "$jar" != *slf4j* ]]; then
    CLASSPATH+=:$jar
  fi
done

# TODO(rxin): Check aux classpath and aux java opts.
#CLASSPATH=${CLASSPATH}:${AUX_CLASSPATH}

export CLASSPATH # Needed for spark-shell

# Mesos related section.
MESOS_CLASSPATH=""
if [ "x$MESOS_JAR" != "x" ] ; then
  MESOS_CLASSPATH="$MESOS_JAR"
fi

if [ "x$SPARK_MEM" == "x" ] ; then
  SPARK_MEM="512m"
fi

export SPARK_MEM # So that the process sees it and can report it to Mesos

# Set JAVA_OPTS to be able to load native libraries and to set heap size
JAVA_OPTS+="$SPARK_JAVA_OPTS"
JAVA_OPTS+=" -Djava.library.path=$SPARK_LIBRARY_PATH"
JAVA_OPTS+=" -Xms$SPARK_MEM -Xmx$SPARK_MEM"
# Load extra JAVA_OPTS from conf/java-opts, if it exists
if [ -e $FWDIR/conf/java-opts ] ; then
  JAVA_OPTS+=" `cat $FWDIR/conf/java-opts`"
fi
export JAVA_OPTS

# In case we are running Ant
export ANT_OPTS=$JAVA_OPTS

if [ -n "$SCALA_HOME" ]; then
  SCALA=${SCALA_HOME}/bin/scala
else
  SCALA=scala
fi

if [ "x$RUNNER" == "x" ] ; then
    RUNNER="$SCALA -cp $CLASSPATH" 
fi

exec $RUNNER "$@"
